{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ad5d91c-923f-4092-b63c-c287fe820526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.driver.port', '33602'),\n",
       " ('spark.app.id', 'app-20210616170511-0000'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.app.name', 'prep_datos'),\n",
       " ('spark.driver.memory', '1g'),\n",
       " ('spark.driver.host', '192.168.0.20'),\n",
       " ('spark.sql.warehouse.dir',\n",
       "  'file:/home/usuarioFAI/notebooks/spark-warehouse'),\n",
       " ('spark.app.startTime', '1623873906193'),\n",
       " ('spark.executor.memory', '1g'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.executor.instances', '1'),\n",
       " ('spark.submit.pyFiles', ''),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.master', 'spark://bigdata-srv.fi.uncoma.edu.ar:7077'),\n",
       " ('spark.ui.showConsoleProgress', 'true'),\n",
       " ('spark.executor.memoryOverhead', '1g')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Configuramos Spark\n",
    "\n",
    "#importo la libreria\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession\\\n",
    ".builder\\\n",
    ".config(\"spark.submit.deployMode\", \"client\")\\\n",
    ".config(\"spark.executor.instances\", \"1\")\\\n",
    ".config(\"spark.executor.memory\", \"1g\")\\\n",
    ".config(\"spark.driver.memory\", \"1g\")\\\n",
    ".config(\"spark.executor.memoryOverhead\", \"1g\")\\\n",
    ".appName(\"prep_datos\")\\\n",
    ".master(\"spark://bigdata-srv.fi.uncoma.edu.ar:7077\")\\\n",
    ".getOrCreate()\n",
    "\n",
    "spark.sparkContext._conf.getAll()  # ver la configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07457749-019f-484a-a668-0173b727ad25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leemos el archivo del servidor hdfs\n",
    "df = spark.read.csv(\"hdfs://localhost:9000/cursoFAI/my_dataset/Water_Quality.csv\", inferSchema=\"true\", header=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "207a491e-2258-4dc2-b3e8-f6e65a61bd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0425194-5e99-49a7-ae79-e24ea7784885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Sample ID: integer (nullable = true)\n",
      " |-- Grab ID: integer (nullable = true)\n",
      " |-- Profile ID: integer (nullable = true)\n",
      " |-- Sample Number: string (nullable = true)\n",
      " |-- Collect DateTime: string (nullable = true)\n",
      " |-- Depth (m): double (nullable = true)\n",
      " |-- Site Type: string (nullable = true)\n",
      " |-- Area: string (nullable = true)\n",
      " |-- Locator: string (nullable = true)\n",
      " |-- Site: string (nullable = true)\n",
      " |-- Parameter: string (nullable = true)\n",
      " |-- Value: double (nullable = true)\n",
      " |-- Units: string (nullable = true)\n",
      " |-- QualityId: integer (nullable = true)\n",
      " |-- Lab Qualifier: string (nullable = true)\n",
      " |-- MDL: double (nullable = true)\n",
      " |-- RDL: double (nullable = true)\n",
      " |-- Text Value: string (nullable = true)\n",
      " |-- Sample Info: string (nullable = true)\n",
      " |-- Steward Note: string (nullable = true)\n",
      " |-- Replicates: integer (nullable = true)\n",
      " |-- Replicate Of: integer (nullable = true)\n",
      " |-- Method: string (nullable = true)\n",
      " |-- Date Analyzed: string (nullable = true)\n",
      " |-- Data Source: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c9103d8-3974-4e37-af20-8567a35d7f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removemos los espacios en las columnas para que sea más sencillo trabajarlos\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "df=df.select([F.col(col).alias(col.replace(' ', '_')) for col in df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56e3f39b-6c29-4a22-baf7-b4adf458a8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Sample_ID: integer (nullable = true)\n",
      " |-- Grab_ID: integer (nullable = true)\n",
      " |-- Profile_ID: integer (nullable = true)\n",
      " |-- Sample_Number: string (nullable = true)\n",
      " |-- Collect_DateTime: string (nullable = true)\n",
      " |-- Depth_(m): double (nullable = true)\n",
      " |-- Site_Type: string (nullable = true)\n",
      " |-- Area: string (nullable = true)\n",
      " |-- Locator: string (nullable = true)\n",
      " |-- Site: string (nullable = true)\n",
      " |-- Parameter: string (nullable = true)\n",
      " |-- Value: double (nullable = true)\n",
      " |-- Units: string (nullable = true)\n",
      " |-- QualityId: integer (nullable = true)\n",
      " |-- Lab_Qualifier: string (nullable = true)\n",
      " |-- MDL: double (nullable = true)\n",
      " |-- RDL: double (nullable = true)\n",
      " |-- Text_Value: string (nullable = true)\n",
      " |-- Sample_Info: string (nullable = true)\n",
      " |-- Steward_Note: string (nullable = true)\n",
      " |-- Replicates: integer (nullable = true)\n",
      " |-- Replicate_Of: integer (nullable = true)\n",
      " |-- Method: string (nullable = true)\n",
      " |-- Date_Analyzed: string (nullable = true)\n",
      " |-- Data_Source: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38410b87-7757-4c52-bfb1-b836edc50b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|           Site_Type| count|\n",
      "+--------------------+------+\n",
      "|         Large Lakes|791824|\n",
      "|  Streams and Rivers|444848|\n",
      "|    Swimming Beaches|   219|\n",
      "|     Marine Offshore|299521|\n",
      "|Freshwater - Unca...|   353|\n",
      "|   Marine Intertidal| 51299|\n",
      "+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby('Site_Type').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d06d6e4-3704-44eb-a4e7-5267bfd0f927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------------------\n",
      " Sample_ID        | 17625                           \n",
      " Grab_ID          | null                            \n",
      " Profile_ID       | 20962                           \n",
      " Sample_Number    | L12637-8                        \n",
      " Collect_DateTime | 01/14/1998 12:48:00 PM          \n",
      " Depth_(m)        | null                            \n",
      " Site_Type        | Streams and Rivers              \n",
      " Area             | Cedar                           \n",
      " Locator          | A438                            \n",
      " Site             | Cedar River at SE Jones Rd      \n",
      " Parameter        | Storm Or Non-Storm              \n",
      " Value            | null                            \n",
      " Units            | none                            \n",
      " QualityId        | 2                               \n",
      " Lab_Qualifier    | null                            \n",
      " MDL              | null                            \n",
      " RDL              | null                            \n",
      " Text_Value       | S                               \n",
      " Sample_Info      | null                            \n",
      " Steward_Note     | null                            \n",
      " Replicates       | null                            \n",
      " Replicate_Of     | null                            \n",
      " Method           | NONE                            \n",
      " Date_Analyzed    | null                            \n",
      " Data_Source      | KCEL                            \n",
      "-RECORD 1-------------------------------------------\n",
      " Sample_ID        | 2244                            \n",
      " Grab_ID          | 2244                            \n",
      " Profile_ID       | 22                              \n",
      " Sample_Number    | L63668-18                       \n",
      " Collect_DateTime | 09/21/2015 10:29:00 AM          \n",
      " Depth_(m)        | 54.2                            \n",
      " Site_Type        | Marine Offshore                 \n",
      " Area             | Central Puget Sound             \n",
      " Locator          | JSUR01                          \n",
      " Site             | Point Wells                     \n",
      " Parameter        | Temperature                     \n",
      " Value            | 13.0                            \n",
      " Units            | deg C                           \n",
      " QualityId        | 1                               \n",
      " Lab_Qualifier    | null                            \n",
      " MDL              | null                            \n",
      " RDL              | null                            \n",
      " Text_Value       | null                            \n",
      " Sample_Info      | null                            \n",
      " Steward_Note     | null                            \n",
      " Replicates       | null                            \n",
      " Replicate_Of     | null                            \n",
      " Method           | CTD                             \n",
      " Date_Analyzed    | 09/21/2015                      \n",
      " Data_Source      | KCEL                            \n",
      "-RECORD 2-------------------------------------------\n",
      " Sample_ID        | 20984                           \n",
      " Grab_ID          | null                            \n",
      " Profile_ID       | 18776                           \n",
      " Sample_Number    | L6509-6                         \n",
      " Collect_DateTime | 07/18/1995 01:05:00 PM          \n",
      " Depth_(m)        | null                            \n",
      " Site_Type        | Streams and Rivers              \n",
      " Area             | Green                           \n",
      " Locator          | 3106                            \n",
      " Site             | Green River at Starfire Way     \n",
      " Parameter        | Turbidity                       \n",
      " Value            | 1.7                             \n",
      " Units            | NTU                             \n",
      " QualityId        | 2                               \n",
      " Lab_Qualifier    | null                            \n",
      " MDL              | 0.5                             \n",
      " RDL              | 1.0                             \n",
      " Text_Value       | null                            \n",
      " Sample_Info      | null                            \n",
      " Steward_Note     | null                            \n",
      " Replicates       | null                            \n",
      " Replicate_Of     | null                            \n",
      " Method           | SM2130-B                        \n",
      " Date_Analyzed    | null                            \n",
      " Data_Source      | KCEL                            \n",
      "-RECORD 3-------------------------------------------\n",
      " Sample_ID        | 192806                          \n",
      " Grab_ID          | null                            \n",
      " Profile_ID       | 80556                           \n",
      " Sample_Number    | L75129-8                        \n",
      " Collect_DateTime | 08/12/2020 12:20:00 PM          \n",
      " Depth_(m)        | null                            \n",
      " Site_Type        | Streams and Rivers              \n",
      " Area             | Rock                            \n",
      " Locator          | LSIN1                           \n",
      " Site             | Rock Creek mouth                \n",
      " Parameter        | Temperature                     \n",
      " Value            | 17.5                            \n",
      " Units            | deg C                           \n",
      " QualityId        | 2                               \n",
      " Lab_Qualifier    | null                            \n",
      " MDL              | null                            \n",
      " RDL              | null                            \n",
      " Text_Value       | null                            \n",
      " Sample_Info      | null                            \n",
      " Steward_Note     | null                            \n",
      " Replicates       | null                            \n",
      " Replicate_Of     | null                            \n",
      " Method           | KCEL SOP# 245                   \n",
      " Date_Analyzed    | 08/12/2020                      \n",
      " Data_Source      | KCEL                            \n",
      "-RECORD 4-------------------------------------------\n",
      " Sample_ID        | 17697                           \n",
      " Grab_ID          | null                            \n",
      " Profile_ID       | 4217                            \n",
      " Sample_Number    | L12817-2                        \n",
      " Collect_DateTime | 03/09/1998 09:40:00 AM          \n",
      " Depth_(m)        | null                            \n",
      " Site_Type        | Streams and Rivers              \n",
      " Area             | McAleer                         \n",
      " Locator          | A432                            \n",
      " Site             | McAleer at Bothell Way NE       \n",
      " Parameter        | Temperature                     \n",
      " Value            | 7.8                             \n",
      " Units            | deg C                           \n",
      " QualityId        | 2                               \n",
      " Lab_Qualifier    | null                            \n",
      " MDL              | null                            \n",
      " RDL              | null                            \n",
      " Text_Value       | null                            \n",
      " Sample_Info      | null                            \n",
      " Steward_Note     | null                            \n",
      " Replicates       | null                            \n",
      " Replicate_Of     | null                            \n",
      " Method           | NONE                            \n",
      " Date_Analyzed    | null                            \n",
      " Data_Source      | KCEL                            \n",
      "-RECORD 5-------------------------------------------\n",
      " Sample_ID        | 131872                          \n",
      " Grab_ID          | null                            \n",
      " Profile_ID       | 51075                           \n",
      " Sample_Number    | L5618-2                         \n",
      " Collect_DateTime | 03/13/1995 09:00:00 AM          \n",
      " Depth_(m)        | null                            \n",
      " Site_Type        | Large Lakes                     \n",
      " Area             | Lake Union/Ship Canal           \n",
      " Locator          | 0540                            \n",
      " Site             | Ship Canal near Montlake Bridge \n",
      " Parameter        | pH, Field                       \n",
      " Value            | 7.46                            \n",
      " Units            | pH                              \n",
      " QualityId        | 2                               \n",
      " Lab_Qualifier    | null                            \n",
      " MDL              | null                            \n",
      " RDL              | null                            \n",
      " Text_Value       | null                            \n",
      " Sample_Info      | null                            \n",
      " Steward_Note     | null                            \n",
      " Replicates       | null                            \n",
      " Replicate_Of     | null                            \n",
      " Method           | null                            \n",
      " Date_Analyzed    | null                            \n",
      " Data_Source      | KCEL                            \n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(n=6, truncate=False, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "801260ed-d744-476e-8e70-43467c25e0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped=df.drop('Grab_ID', 'Profile_ID', 'Sample_Number', 'QualityId', 'Lab_Qualifier', 'MDL', 'RDL', 'Text_Value',\n",
    "                  'Sample_Info', 'Steward_Note', 'Replicates', 'Replicate_Of', 'Method', 'Date_Analyzed', 'Data_Source')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7c7ef54-d1c6-4cf8-8943-045b33550f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Sample_ID: integer (nullable = true)\n",
      " |-- Collect_DateTime: string (nullable = true)\n",
      " |-- Depth_(m): double (nullable = true)\n",
      " |-- Site_Type: string (nullable = true)\n",
      " |-- Area: string (nullable = true)\n",
      " |-- Locator: string (nullable = true)\n",
      " |-- Site: string (nullable = true)\n",
      " |-- Parameter: string (nullable = true)\n",
      " |-- Value: double (nullable = true)\n",
      " |-- Units: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dropped.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a637a504-5ddb-41c8-9455-e7274320e360",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A partir de aquí generaremos dos archivos, uno para los lagos y otros para los rios\n",
    "df_lakes=df_dropped.select(\"*\").where(df_dropped.Site_Type==\"Large Lakes\").toPandas()\n",
    "df_rivers=df_dropped.select(\"*\").where(df_dropped.Site_Type==\"Streams and Rivers\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "238602dd-2666-4787-813f-d629cb726ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#leemos el archivo de puntos geográficos\n",
    "df_sites = spark.read.csv(\"hdfs://localhost:9000/cursoFAI/my_dataset/WLRD_Sites.csv\", inferSchema=\"true\", header=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0dd033ff-1365-442a-bdef-788a5d82afbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- SiteName: string (nullable = true)\n",
      " |-- Locator: string (nullable = true)\n",
      " |-- Latitude: double (nullable = true)\n",
      " |-- Longitude: double (nullable = true)\n",
      " |-- Site Type: string (nullable = true)\n",
      " |-- Area: string (nullable = true)\n",
      " |-- New Georeferenced Column: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sites.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61594ae8-c616-4820-bba0-b27421814f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#primero quitamos los espacios de los nombres de las columnas\n",
    "df_sites=df_sites.select([F.col(col).alias(col.replace(' ', '_')) for col in df_sites.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0279ff3-b62f-4070-b5f5-da5d74656578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- SiteName: string (nullable = true)\n",
      " |-- Locator: string (nullable = true)\n",
      " |-- Latitude: double (nullable = true)\n",
      " |-- Longitude: double (nullable = true)\n",
      " |-- Site_Type: string (nullable = true)\n",
      " |-- Area: string (nullable = true)\n",
      " |-- New_Georeferenced_Column: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sites.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21c5e8b2-b43b-4589-bc85-9b0555d9d49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#como solo nos interesa el locator, siteName, latitud, longitud y punto geográfico dropeamos el resto antes del join\n",
    "df_sites_dropped=df_sites.drop('Site_Type', 'Area')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00595341-c0d0-4af5-8c82-c862cc4a8045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- SiteName: string (nullable = true)\n",
      " |-- Locator: string (nullable = true)\n",
      " |-- Latitude: double (nullable = true)\n",
      " |-- Longitude: double (nullable = true)\n",
      " |-- New_Georeferenced_Column: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sites_dropped.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4f56731-d8e1-46f8-92cb-a57fd601357f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convertimos a pandas\n",
    "df_sites_pd=df_sites_dropped.toPandas()\n",
    "#realizamos el merge de cada uno\n",
    "df_lakes_merged=pd.merge(df_lakes, df_sites_pd, on=\"Locator\")\n",
    "df_rivers_merged=pd.merge(df_rivers, df_sites_pd, on=\"Locator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "344161ec-ee08-4679-8f78-fedf20d73830",
   "metadata": {},
   "outputs": [],
   "source": [
    "#guardamos los csvs para trabajarlos por separado\n",
    "df_lakes_merged.to_csv(r'/home/usuarioFAI/datasets/my_dataset/partitions/lakes.csv')\n",
    "df_rivers_merged.to_csv(r'/home/usuarioFAI/datasets/my_dataset/partitions/rivers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b41cc5a-c515-4c75-a043-5262a015bdc3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ChunkedEncodingError",
     "evalue": "('Connection broken: IncompleteRead(0 bytes read, 2 more expected)', IncompleteRead(0 bytes read, 2 more expected))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIncompleteRead\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/env3/lib/python3.9/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_error_catcher\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    437\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m                 \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env3/lib/python3.9/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread_chunked\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    766\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m                 \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    768\u001b[0m                 decoded = self._decode(\n",
      "\u001b[0;32m~/env3/lib/python3.9/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_handle_chunk\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mreturned_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Toss the CRLF at the end of the chunk.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36m_safe_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    610\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIncompleteRead\u001b[0m: IncompleteRead(0 bytes read, 2 more expected)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mProtocolError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/env3/lib/python3.9/site-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    752\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env3/lib/python3.9/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunked\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_chunked_reads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env3/lib/python3.9/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread_chunked\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_response\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 793\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env3/lib/python3.9/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_error_catcher\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    454\u001b[0m                 \u001b[0;31m# This includes IncompleteRead.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mProtocolError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Connection broken: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mProtocolError\u001b[0m: ('Connection broken: IncompleteRead(0 bytes read, 2 more expected)', IncompleteRead(0 bytes read, 2 more expected))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mChunkedEncodingError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-d3072ee3e7eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdir_archivo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/home/usuarioFAI/datasets/my_dataset/partitions/lakes.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdir_destino\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/cursoFAI/my_dataset/partitions/lakes.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0msubir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_destino\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdir_archivo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mdir_archivo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/home/usuarioFAI/datasets/my_dataset/partitions/rivers.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdir_destino\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/cursoFAI/my_dataset/partitions/rivers.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env3/lib/python3.9/site-packages/hdfs/client.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(self, hdfs_path, local_path, n_threads, temp_dir, chunk_size, progress, cleanup, **kwargs)\u001b[0m\n\u001b[1;32m    540\u001b[0m     \u001b[0mtemp_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m       \u001b[0mstatuses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhdfs_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHdfsError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'not a directory'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env3/lib/python3.9/site-packages/hdfs/client.py\u001b[0m in \u001b[0;36mlist\u001b[0;34m(self, hdfs_path, status)\u001b[0m\n\u001b[1;32m   1078\u001b[0m     \u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Listing %r.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdfs_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1079\u001b[0m     \u001b[0mhdfs_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhdfs_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1080\u001b[0;31m     \u001b[0mstatuses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_list_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhdfs_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'FileStatuses'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'FileStatus'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1081\u001b[0m     if len(statuses) == 1 and (\n\u001b[1;32m   1082\u001b[0m       \u001b[0;32mnot\u001b[0m \u001b[0mstatuses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pathSuffix'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhdfs_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'FILE'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env3/lib/python3.9/site-packages/hdfs/client.py\u001b[0m in \u001b[0;36mapi_handler\u001b[0;34m(client, hdfs_path, data, strict, **params)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m           res = client._request(\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env3/lib/python3.9/site-packages/hdfs/client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, method, url, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \"\"\"\n\u001b[0;32m--> 209\u001b[0;31m     return self._session.request(\n\u001b[0m\u001b[1;32m    210\u001b[0m       \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m       \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env3/lib/python3.9/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    540\u001b[0m         }\n\u001b[1;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env3/lib/python3.9/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env3/lib/python3.9/site-packages/requests/models.py\u001b[0m in \u001b[0;36mcontent\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    829\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONTENT_CHUNK_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34mb''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content_consumed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env3/lib/python3.9/site-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    754\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mChunkedEncodingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mDecodeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mContentDecodingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mChunkedEncodingError\u001b[0m: ('Connection broken: IncompleteRead(0 bytes read, 2 more expected)', IncompleteRead(0 bytes read, 2 more expected))"
     ]
    }
   ],
   "source": [
    "#vamos a subir a hdfs\n",
    "# importar hdfs\n",
    "from hdfs import InsecureClient\n",
    "#conectarme\n",
    "client = InsecureClient('http://localhost:9870', user='usuarioFAI')\n",
    "#subimos los archivos a hdfs\n",
    "dir_archivo=\"/home/usuarioFAI/datasets/my_dataset/partitions/lakes.csv\"\n",
    "dir_destino=\"/cursoFAI/my_dataset/partitions/lakes.csv\"\n",
    "subir = client.upload(dir_destino,dir_archivo)\n",
    "dir_archivo=\"/home/usuarioFAI/datasets/my_dataset/partitions/rivers.csv\"\n",
    "dir_destino=\"/cursoFAI/my_dataset/partitions/rivers.csv\"\n",
    "subir = client.upload(dir_destino,dir_archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "526ebf1e-c722-4a21-bc19-2f7330f3a65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cierro la sesión\n",
    "spark.sparkContext.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17ad143-3b99-4afe-b383-bf8f7881e51c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
